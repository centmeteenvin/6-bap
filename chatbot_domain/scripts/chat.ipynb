{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc34acb-bcf0-4c2f-929b-651a109d7923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\Documents\\school\\Unief-6\\6-bap\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\vince\\\\Documents\\\\school\\\\Unief-6\\\\6-bap'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd C:/Users/vince/Documents/school/Unief-6/6-bap\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "859fb512-68fb-48bd-9948-afd37563f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatbot_domain.chatbot import *\n",
    "from chatbot_domain.rag import VectorRetriever, FacebookDPR\n",
    "from chatbot_domain import logger\n",
    "from chatbot_domain.data import loadDataSetFromDisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dd3a9f7-24d5-405a-a283-ea60877ed741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n",
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2024-04-10 13:26:49,350 - chatbot_domain - INFO - Loading dataset from ./ragDataSet\n",
      "2024-04-10 13:26:49,364 - chatbot_domain - INFO - Adding faiss Indices\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031cef120b4a477ca74769bdeb9a2ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 13:26:49,508 - chatbot_domain - INFO - Saving modified dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5bf3cc7a1a4296bf5ca669566d9102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/15728 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger.setLevel('DEBUG')\n",
    "dpr = FacebookDPR()\n",
    "dataset = loadDataSetFromDisk('./ragDataSet')['train']\n",
    "retriever = VectorRetriever(dataset=dataset, dpr=dpr, datasetLocation='./ragDataSet')\n",
    "chatbot = ChatBotBuilder(OpenAIChatBot()).rag(retriever, 2048).domainGuard(DIPDomainGuard).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba00a44c-7b84-4067-8119-2be874bd2384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 13:27:12,962 - chatbot_domain - DEBUG - The final prompt is How do you calculate a discrete 2 dimensional gradiant\n",
      "2024-04-10 13:27:12,963 - chatbot_domain - DEBUG - The added role was You are an assistant with expertise in the Digital Image Processing (DIP) domain. Your knowledge is given through the 'CONTEXT' section. You will no answer any questions that are not related to the DIP domain. If you are not confident in your answer you will tell us so. If the question is not related to the domain you will answer with 'This question is out of my domain of knowledge'\n",
      "2024-04-10 13:27:13,435 - chatbot_domain - DEBUG - Context concatenation loop completed without breaking, updating sampleGuess to 20\n",
      "2024-04-10 13:27:13,436 - chatbot_domain - DEBUG - rerunning context gathering with higher samples\n",
      "2024-04-10 13:27:13,547 - chatbot_domain - DEBUG - Context concatenation loop completed without breaking, updating sampleGuess to 40\n",
      "2024-04-10 13:27:13,548 - chatbot_domain - DEBUG - rerunning context gathering with higher samples\n",
      "2024-04-10 13:27:13,600 - chatbot_domain - DEBUG - Context concatenation loop completed without breaking, updating sampleGuess to 80\n",
      "2024-04-10 13:27:13,601 - chatbot_domain - DEBUG - rerunning context gathering with higher samples\n",
      "2024-04-10 13:27:13,653 - chatbot_domain - DEBUG - Had to cutoff the context due to the context window limit. updating sampleGuess to 41\n",
      "2024-04-10 13:27:13,655 - chatbot_domain - DEBUG - The added context was \n",
      "Alternative definition An alternative definition of the opening will allow us to determine the opening in a single step process.\n",
      "Either the objective is to have the DIP draw some conclusions from the incoming images and pass them on to a controller that can take appropriate action e.g. sending a positive identification for the species oak to the TreeGPS database when an oak has been identified.\n",
      "The geodesic operations will enable us to fully reconstruct parts of an image.\n",
      "Alternative definition An alternative definition of the closing will allow us to determine the closing in a single step process.\n",
      "6.3. COLOR 119 .1 XYZ 380410430460 490 520 550 580 610640 Figure 6.12 The trichromatic normalization plane added to the monochromatic trajectory graph of Fig ure6.11 on page 117 perceptions as any of these points can be created by a weighted combination of pure monochromatic colors. This is based on the assumption that our vision is linear with respect to color perception. Points outside of the color gamut dont correspond to tristimulus signals that will ever occur in a normal brain.\n",
      "The concepts of translation and reflection have been illustrated in Figure 7.4.\n",
      "20 CHAPTER 3. IMAGEPROCESSINGSYSTEMS  !\u001c8 ADC Image detection systemDIPPlant ControllerDAC \u001c  Image generation system Figure 3.1 Generic structure of an image processing system electrical signals using an amplifier \u001c8. These electrical signals subsequently are quantized by anto an image that can be treated by the Digital Image Processor DIP. Very often the chain from sensor to ADC is integrated into a standalone image detection system e.g. a CMOScamera.\n",
      "8.4.4.2 Regional analysis  piecewise linear edge modeling We will restrict ourselves to one particular regional method i.e. creating a polylinear model based on an ordered set of edge pixels. A second prerequisite is that we need to know if the edge is a closed or an open path. If it is an open path we can apply the algorithm straight away. If it a closed path we need to split it into two open half paths.\n",
      "We will treat three methods a local one a regional one and a global one. While the local method is not a very good one  we added it for completeness  the latter two are good performers.\n",
      "The iterative application of the geodesic dilation converges to a stable image.2Applying it until convergence occurs is the socalled reconstruction by dilation and is denoted as   withsuch that1  .\n",
      "A.1 Experiments and outcomes The very basic concept of stochastic theory is the experiment . Consider it to be a particular action that one can take repeatedly  and leads to a specific outcome a result.\n",
      "The principle is to subtract an eroded version of the image from a dilated version of the image.\n",
      "A.2 Events An event is a subset of the outcome set. If the outcome of an experiment is part of this subset then we say theeventhappened . If it is not a part of the event subset then we say theeventdidnot happen.\n",
      "Thesecond observation is that in the framework of digital signal processing we tend to measure physical quantities using a twostep process.\n",
      "In that sense this is the first chapter in which we will perform image analysis rather than image processing . Remember the former means determining characteristics of an image while the latter means processing one image into another see section 3.3 on page 20 .\n",
      "4.3 Resampling 4.3.1 The need for resampling Given the fact that we have a sampled version of the image we want to consider one might wonder why do we need resampling?\n",
      "The result can be observed in Figure 6.23. If you look carefully you will see the artifacts in the resulting image at the edge of the earths disc.\n",
      "Example As an example consider the histogram data below. It belongs to two simple 1111 test images and quantized using 3bitintensity values . Imageagain corresponds to Figure5.3 on page 70 . Imageis in fact nonexistent. The histogram is just a linear decreasing histogram for testing purposes.\n",
      "186 CHAPTER 7. MATHEMATICALMORPHOLOGY As an example consider the image in Figure 7.27a. We indicated a small rectangular cutout on the image that we will study in detail. The cutout is taken from the radiator grille of the toy car on the left. A magnified version of the cutout can be found in Figure 7.27b the corresponding intensity values can be found in Figure 7.27c.\n",
      "Frequently the image is converted to a binary image first followed by a distance transformation before it is subjected to watershed segmentation.\n",
      "The resulting histogram after transformation can be found in Figure 5.13. The resulting image is shown in Figure 5.14. As you can see the resulting histogram is not uniform at all. This is due to the fact that for discrete random variables the equalization property does not hold.\n",
      "Principle Consider a line in a two dimensional Cartesian space the GHspace or socalled data space .\n",
      "Lets replace the dilation with a reconstruction by dilation such that the original objects are fully restored without letting the brushs shape interfere.4 4Of course the structuring element of the dilation should be versatile enough to allow reconstruction in all de sired directions.\n",
      "Remarks This is typically done by finding corresponding control points in the two images followed by the quest for a transformation that relates the corresponding control points.\n",
      "The origin is the spot where you grab the structuring element to later translate it or to rotate it180to reflect it. An example of a structuring element can be found in Figure 7.5. The example given is quite uncommon but still a valid structuring element. Often structuring elements are symmetrical around the origin. In the graphical representation the origin is indicated using a circle. In the matrix representation on the right a value of 1 means the pixel is in the SE a value of 0means it is not in the SE. It is also assumed one can indicate the origin e.g. using boldface or with a circle. If not the SE is extended with extra zero columns or rows such that the origin lies in the middle. E.g. Matlab does not allow boldface or circles around values so there extra zeros are added and the origin is the center pixel.\n",
      "By discretizing images we transform them to the domain where digital computers are at their best number crunching.\n",
      "To this end we need an estimator that fulfills one important condition. The imposed derivative on the upper boundary of a unit cell  H 1 needs to be the same as the derivative imposed on the lower boundary of the neighboring cell that abuts to the right. Likewise the imposed derivative on the lower boundary  H 0 needs to be the same as the imposed derivative on the upper boundary of the neighboring cell that abuts to the left.\n",
      "For that case the issue has been illustrated in Figure 4.10 on the next page . Subfigure a shows a discretetime signal that wed like to resample. The desired offgrid new sample locations have been indicated in subfigure b. The key question is how do we find sensible DIP20233.9TB Digital Image Processing  Text book\n",
      "Either the objective is to manipulate the incoming images to produce new images and display them to a user. In that case we proceed further to the right converting our digital images again to the analog domain using a DAC converter and an amplifier \u001cto drive the image actuatorthat displays the resulting image as seen by our eye. Very often these last parts starting from the DAC are integrated into a standalone image generation system e.g. an LCD monitor.\n",
      "GH 1 GH 4.4.4 Common geometric transformations In this section we will discuss a number of common geometric transformations. We will limit ourselves to transformations that maintain lines. We will consider Linear transformations Affine transformations Projective transformations The former two maintain the parallelism of lines. The latter does not. Instead it allows to correct or invoke perspective in the image.\n",
      "If we categorize electromagnetic waves in vacuum according to their frequency or wavelength we obtain the spectrum of Figure 6.1. Light is only a small subset of that entire spectrum. Visible light ranges from 400 nm violet to 700 nm red. The neighbors of that range ultra violet below 400 nm and infra red above 700 nm are often also considered to be non visible light. It might be obvious to you that we use colors to name the different wavelengths. However if youre stupefied by that fact bear a little longer it will become clear when discussing the human eye in section 6.2 on page 112 .\n",
      "This work in particular was inspired by some of them you can find in the reference list at the end Jäh02GW07GWE09 Wal08Mal09. So why write another introductorylevel text on the very same subject? It allows treating the subjects at a level appropriate to undergraduates in Applied Engineering. There is almost no textbook available that has the correct mix of mathematics and engineering. Writing my own course material also allows elaborating difficult subjects based on teaching experience and updating evolving subjects swiftly.\n",
      "7.3.5.4 Convex hull determination In many cases processing a full image with complex imaging algorithms requires too much computing power. Determination of a region of interest is required to allow focusing the image analysis onto a specific part of the image. Usually the shape of the hull around the object of interest should not be overly complex. Demanding it to be rectangular or diamondshaped might seem appropriate.\n",
      "The discetization can take place at different stages of the image processing chain. It can take place in the image detector. It also can take place at a later stage as part of the Digital Image Processing DIP itself.\n",
      "This calls for a new type of color model. One that does not base itself on a particular choice of red green or blue but that is device independent .\n",
      "System In Out Imaging system Sensor data Images Image processing system Images Images Image analysis system Images Data Image recognition system Images Recognized objects Image synthesis system Data Images Remarks Computer vision is the term used for a specific kind of image recognitioninterpretation system in which no human intervention is required. The computer draws conclusions and acts upon them autonomously.\n",
      "determination charts in biology or syntaxgrammar descriptions in linguistics. These are also very rigorous treatments of the science of shapes and forms. So theres no reason to be posh about the fact that we will be doing this in a mathematical manner.\n",
      "Still it is important to realize that color is not a physical concept. It is our impression of the effect waves with different wavelengths have on the cones in our eyes. This makes color a difficult and partly an artificial concept. Our eyes cannot measure wavelength. Color is how our brain translates wavelengths in sensations.\n",
      "Uniform vs. graded quantization If all intervals are equal in size we are using socalled uniform quantization . Using intervals that are not of equal size is called nonuniform or graded quantization . Alaw or law quantization employed in cellphone communications are examples of the latter.\n",
      "Definition Opening of grayscale images The opening of a grayscale image 5with a structuring ele ment1yields a new image 6and is denoted as 651 and defined as 51511.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This question is within my domain of knowledge. To calculate the discrete 2-dimensional gradient, you can use finite differences. The gradient in the x direction can be approximated by subtracting neighboring pixel values horizontally, and the gradient in the y direction can be approximated by subtracting neighboring pixel values vertically. This can be represented mathematically as ∇f(x, y) = [∂f/∂x, ∂f/∂y].\n"
     ]
    }
   ],
   "source": [
    "question = input(\"> \")\n",
    "answer = chatbot.askQuestion(question)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
